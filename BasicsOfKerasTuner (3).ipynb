{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d47649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3b4bbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be956b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Z=[]\n",
    "IMG_SIZE=150\n",
    "FLOWER_DAISY_DIR='C:/Users/91914/Downloads/archive (3)*/daisy'\n",
    "FLOWER_SUNFLOWER_DIR='../input/flowers/flowers/sunflower'\n",
    "FLOWER_TULIP_DIR='../input/flowers/flowers/tulip'\n",
    "FLOWER_DANDI_DIR='../input/flowers/flowers/dandelion'\n",
    "FLOWER_ROSE_DIR='../input/flowers/flowers/rose'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8adedb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e9dcc2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m (train_images),(test_images)\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/91914/Downloads/archive (3)*/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "(train_images),(test_images)=(\"C:/Users/91914/Downloads/archive (3)*/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e665e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images/255.0\n",
    "test_images=test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42102ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[0].shape\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e011bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images.reshape(len(train_images),28,28,1)\n",
    "test_images=test_images.reshape(len(test_images),28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12c8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#two types selectors functions: 1. INT  2. Choice\n",
    "def build_model(hp):  \n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),#min value of filter you want\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),#picks like mcq\n",
    "        activation='relu',\n",
    "        input_shape=(28,28,1)\n",
    "    ),\n",
    "      #for i in range(0,hp.Int(....)) this will also work\n",
    "    keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),# ihave added this line extra in comparison to the old model\n",
    "        kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),\n",
    "        activation='relu'\n",
    "    ),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(\n",
    "        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n",
    "        activation='relu'\n",
    "    ),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "  ])\n",
    "  \n",
    "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aae7bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "#hyprer/paramter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1827beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_search=RandomSearch(build_model,\n",
    "                          objective='val_accuracy',\n",
    "                          max_trials=5,directory='output',project_name=\"Mnist34569Fashion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7591e1bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tuner_search.search(train_images,train_labels,epochs=3,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb087bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tuner_search.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c032c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(train_images, train_labels, epochs=4, validation_split=0.1, initial_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e473d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c175bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1=np.argmax(z,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f323270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24277aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c859af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(z1,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a39af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump,load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461b57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model,'basic.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67105eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a hypertuned model on flower dataset already sent to you\n",
    "#final week:\n",
    "# 1. read YOLO  material\n",
    "# 2. try to use yolo on your own\n",
    "# 3. read about video to image conversion on youtube(search video to frames and then back on youtube)//i will provide link\n",
    "# on next wednesday our project will be over.\n",
    "# submit all due assignments by then\n",
    "#deadline for this ill be 19th and todays assignment will be 19h for y20s and y19s\n",
    "# for 21s assignments must be submitted before 22nd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd07ccec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
